{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Unsupervised.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","authorship_tag":"ABX9TyMf/nUgpPtuEAA8CkWdFScx"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"4YkYFFOJraCe"},"outputs":[],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["import nibabel as nib\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pickle\n","import math\n","\n","import torch\n","import torchvision\n","import torchvision.transforms as transforms\n","from torch.utils.data import Dataset, DataLoader\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim"],"metadata":{"id":"CngDjdlPrh--","executionInfo":{"status":"ok","timestamp":1651510546846,"user_tz":300,"elapsed":2429,"user":{"displayName":"Henry Bulluck","userId":"13348953596629209835"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["# Reads data from a pickle file\n","# Data is stored as a lists of images and ground truths in a dictionary\n","# Each index in the seperate list corrispond to each other\n","class PickleDataset(Dataset):\n","  def __init__(self, pickle_path, transform=None):\n","    # Opens file and reads lists in\n","    file = open(pickle_path, 'rb')\n","    data = pickle.load(file)\n","    file.close()\n","    self.features = data[\"features\"]\n","    self.labels = data[\"labels\"]\n","    #\n","    self.transform = transform\n","\n","  def __len__(self):\n","    return self.features.shape[0]\n","\n","  def __getitem__(self, idx):\n","    feature = self.features[idx]\n","    label = self.labels[idx]\n","\n","    x = [1*(label==0),1*(label==1),1*(label==2),1*(label==3)]\n","    label = torch.tensor(x)\n","    # label = torch.tensor(label).unsqueeze(0)\n","\n","\n","    if self.transform:\n","      feature = self.transform(feature)\n","\n","    return feature, label\n"],"metadata":{"id":"4kqz_qG7rjUE","executionInfo":{"status":"ok","timestamp":1651510546846,"user_tz":300,"elapsed":2,"user":{"displayName":"Henry Bulluck","userId":"13348953596629209835"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["## Training Data"],"metadata":{"id":"Al-Cgn9Yronx"}},{"cell_type":"code","source":["train_path = 'drive/MyDrive/College/Research/ACDC_DataSet/processed_henry/train_data.pkl'\n","\n","# # Set seed for repeatability\n","seed_val = 1\n","torch.manual_seed(seed_val)\n","np.random.seed(seed_val)\n","\n","# Define the validation ratio to be used\n","valid_ratio = 0.9\n","\n","transform = torchvision.transforms.Compose([\n","          transforms.ToTensor(),\n","          transforms.Normalize((0.1307,), (0.3081,))\n","          ])\n","label_transform = transforms.ToTensor()\n","\n","train_dataset = PickleDataset(train_path, transform=transform)#, target_transform=label_transform)\n","\n","# Number of images to use for training\n","nb_train = math.ceil((1.0 - valid_ratio) * len(train_dataset))\n","# Number of images to use for validation\n","nb_valid =  math.floor(valid_ratio * len(train_dataset))\n","\n","# Randomly split into training and validation data\n","train_dataset, valid_dataset = torch.utils.data.dataset.random_split(train_dataset, [nb_train, nb_valid])\n","\n","print(f\"Training dataset length: {len(train_dataset)}\")\n","print(f\"Valid dataset length: {len(valid_dataset)}\")\n","\n","# create your dataloaders\n","train_dataloader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n","valid_dataloader = DataLoader(valid_dataset, batch_size=20, shuffle=True)\n","\n","print(f\"Training batches: {len(train_dataloader)}\")\n","print(f\"Valid batches: {len(valid_dataloader)}\")"],"metadata":{"id":"PluuwnQarplp"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Test Data"],"metadata":{"id":"AjhLVB97ru8n"}},{"cell_type":"code","source":["test_path = 'drive/MyDrive/College/Research/ACDC_DataSet/processed_henry/test_data.pkl'\n","\n","test_dataset = PickleDataset(test_path, transform=transform)#, target_transform=label_transform)\n","print(f\"Training dataset length: {len(train_dataset)}\")\n","test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=True)\n","print(f\"Test batches: {len(test_dataloader)}\")"],"metadata":{"id":"pBThursWrvYU"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Define Network"],"metadata":{"id":"mp3An8-kr994"}},{"cell_type":"code","source":["# Two 3x3 convolutions that maintain image size\n","# Each convolution is followed by a relu activation\n","# Inputs\n","#   in_c: number of channels/features inputted into the convolution\n","#   mid_c: number of channels/features between the two convolutions\n","#   out_c: number of channels/features outputted by the convolution\n","def double_conv(in_c, mid_c, out_c):\n","  conv = nn.Sequential(\n","      nn.Conv2d(\n","        in_channels = in_c,              \n","        out_channels = mid_c,            \n","        kernel_size = 3,                                 \n","        padding = 1                 \n","      ),                              \n","      nn.ReLU(inplace=True),\n","      nn.Conv2d(\n","        in_channels = mid_c,              \n","        out_channels = out_c,            \n","        kernel_size = 3,\n","        padding = 1                            \n","      ),                              \n","      nn.ReLU(inplace=True)\n","  )\n","  return conv"],"metadata":{"id":"ayNdg8pHr3ZC","executionInfo":{"status":"ok","timestamp":1651510556840,"user_tz":300,"elapsed":5,"user":{"displayName":"Henry Bulluck","userId":"13348953596629209835"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["class Generator(nn.Module):\n","  def __init__(self):\n","    super(Generator, self).__init__()\n","    # encoder\n","    self.pool = nn.MaxPool2d(kernel_size=2, stride = 2) #Max pool, decreases image size by half in each dimension, by 4 total\n","    # each convolution increases features by 2 (exception in down_conv1)\n","    self.down_conv1 = double_conv(1, 64, 64)\n","    self.down_conv2 = double_conv(64, 128, 128)\n","    # bottle conv\n","    self.bottle_conv = double_conv(128, 256, 128) #Exapanda and contracts features\n","    # decoder\n","    # each transpose convolution increases image size by 2 in each dimension, 4 in total\n","    # each up_conv decreases features by 4\n","    self.trans1 = nn.ConvTranspose2d(128, 128, kernel_size=3, stride=2, padding=1, output_padding=1)\n","    self.up_conv1 = double_conv(256, 128, 64)\n","    self.trans2 = nn.ConvTranspose2d(64, 64, kernel_size=3, stride=2, padding=1, output_padding=1)\n","    self.up_conv2 = double_conv(128, 64, 64)\n","    # returns number of features equal to classes (4)\n","    self.out = nn.Conv2d(in_channels = 64, out_channels = 4, kernel_size = 3, padding = 1)\n","\n","  def forward(self,img):\n","    # encoder\n","    # a down convolution followed by max pool\n","    # increases features by 2, decreases image size by 4\n","    #------------------------\n","    x1 = self.down_conv1(img)\n","    p1 = self.pool(x1)\n","    #------------------------\n","    x2 = self.down_conv2(p1)\n","    p2 = self.pool(x2)\n","    #------------------------\n","    # bottleneck\n","    # adds more weights for network to change\n","    #------------------------\n","    bottle = self.bottle_conv(p2)\n","    #------------------------\n","    # decoder\n","    # First increases image size\n","    # Then concatanates a similar sized output from a down_conv to the results\n","    # Then does an up_conv decreasing features\n","    #------------------------\n","    u2 = self.trans1(bottle)\n","    c2 = torch.cat([x2,u2], dim=1)\n","    y2 = self.up_conv1(c2)\n","    #------------------------\n","    u1 = self.trans2(y2)\n","    c1 = torch.cat([x1,u1], dim=1)\n","    y1 = self.up_conv2(c1)\n","    #------------------------\n","    # retirns image with proper number of features\n","    out = self.out(y1)\n","    return out\n","\n","  # Initializes model with normally distributed xavier weights for all convolutions\n","  # uses gain of sqrt(2)\n","  def initialize_weights(self):\n","    for m in self.modules():\n","      if isinstance(m, nn.Conv2d):\n","        nn.init.xavier_normal(m.weight,gain=np.sqrt(2))"],"metadata":{"id":"iVHTuk3kG4H_","executionInfo":{"status":"ok","timestamp":1651510556841,"user_tz":300,"elapsed":5,"user":{"displayName":"Henry Bulluck","userId":"13348953596629209835"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["class Descriminator(nn.Module):\n","  def __init__(self):\n","    super(Descriminator, self).__init__()\n","    self.conv1 = nn.Sequential(\n","        double_conv(4,16,16),\n","        nn.MaxPool2d(kernel_size=2, stride = 2)\n","    )\n","    self.conv2 = nn.Sequential(\n","        double_conv(16,32,32),\n","        nn.MaxPool2d(kernel_size=2, stride = 2)\n","    )\n","    self.conv3 = nn.Sequential(\n","        double_conv(32,64,64),\n","        nn.MaxPool2d(kernel_size=2, stride = 2)\n","    )\n","    self.conv4 = nn.Sequential(\n","        double_conv(64,128,128),\n","        nn.MaxPool2d(kernel_size=2, stride = 2)\n","    )\n","\n","    self.linear1 = nn.Sequential(\n","        nn.Linear(in_features = 128*16*16, out_features=256),\n","        nn.ReLU(inplace=True)\n","    )\n","    self.linear2 = nn.Sequential(\n","        nn.Linear(in_features = 256, out_features=64),\n","        nn.ReLU(inplace=True)\n","    )\n","    self.linear3 = nn.Sequential(\n","        nn.Linear(in_features = 64, out_features=16),\n","        nn.ReLU(inplace=True)\n","    )\n","    self.linear4 = nn.Linear(in_features = 16, out_features=1)\n","\n","  def forward(self,x):\n","    x = self.conv1(x)\n","    x = self.conv2(x)\n","    x = self.conv3(x)\n","    x = self.conv4(x)\n","\n","    x = x.view(x.size(0), -1)\n","\n","    x = self.linear1(x)\n","    x = self.linear2(x)\n","    x = self.linear3(x)\n","    x = self.linear4(x)\n","    return x\n","\n","  def initialize_weights(self):\n","    for m in self.modules():\n","      if isinstance(m, nn.Conv2d):\n","        nn.init.xavier_normal(m.weight,gain=np.sqrt(2))"],"metadata":{"id":"gvC6OUifG_kY","executionInfo":{"status":"ok","timestamp":1651510556842,"user_tz":300,"elapsed":6,"user":{"displayName":"Henry Bulluck","userId":"13348953596629209835"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["# Selects device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","print(device)"],"metadata":{"id":"QG7VWvw3Y8_R"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Activation_g(nn.Module):\n","  def __init__(self,divergence=\"GAN\"):\n","    super(Activation_g,self).__init__()\n","    self.divergence =divergence\n","    print(\"Activation computed using \",divergence)\n","\n","  def forward(self,v):\n","    divergence = self.divergence\n","    if divergence == \"KLD\":\n","      return v\n","    elif divergence == \"RKL\":\n","      return -torch.exp(-v)\n","    elif divergence == \"CHI\":\n","      return v\n","    elif divergence == \"SQH\":\n","      return 1-torch.exp(-v)\n","    elif divergence == \"JSD\":\n","      return torch.log(torch.tensor(2.))-torch.log(1.0+torch.exp(-v))\n","    elif divergence == \"GAN\":\n","      return -torch.log(1.0+torch.exp(-v)) # log sigmoid\n","\n","class Conjugate_f(nn.Module):\n","  def __init__(self,divergence=\"GAN\"):\n","    super(Conjugate_f,self).__init__()\n","    self.divergence = divergence\n","    print(\"Conjugate computed using \",divergence)\n","\n","  def forward(self,t):\n","    divergence= self.divergence\n","    if divergence == \"KLD\":\n","      return torch.exp(t-1)\n","    elif divergence == \"RKL\":\n","      return -1 -torch.log(-t)\n","    elif divergence == \"CHI\":\n","      return 0.25*t**2+t\n","    elif divergence == \"SQH\":\n","      return t/(torch.tensor(1.)-t)\n","    elif divergence == \"JSD\":\n","      return -torch.log(2.0-torch.exp(t))\n","    elif divergence == \"GAN\":\n","      return  -torch.log(1.0-torch.exp(t))\n","\n","class VLOSS(nn.Module):\n","  def __init__(self,divergence=\"GAN\"):\n","    super(VLOSS,self).__init__()\n","    self.activation = Activation_g(divergence)\n","  def forward(self,v):\n","    return torch.mean(self.activation(v))\n","\n","\n","class QLOSS(nn.Module):\n","  def __init__(self,divergence=\"GAN\"):\n","    super(QLOSS,self).__init__()\n","    self.conjugate = Conjugate_f(divergence)\n","    self.activation = Activation_g(divergence)\n","  def forward(self,v):\n","    return torch.mean(-self.conjugate(self.activation(v))) "],"metadata":{"id":"zQLrGdhsVfWB","executionInfo":{"status":"ok","timestamp":1651510557168,"user_tz":300,"elapsed":3,"user":{"displayName":"Henry Bulluck","userId":"13348953596629209835"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["#Model parameters\n","params = {'beta1': 0.5, 'beta2': 0.999,'lr_g':0.00001,'lr_d':0.001,'max_epochs':400}\n","\n","# Selects loss function\n","# params['divergence'] = \"SQH\"\n","params['divergence'] = \"GAN\"\n","# params['divergence'] = \"RKL\"\n","# params['divergence'] = \"KLD\"\n","# params['divergence'] = \"JSD\"\n","# params['divergence'] = \"CHI\"\n","\n","#Creates Models\n","D = Descriminator().to(device)\n","G = Generator().to(device)\n","#Optimizers\n","G_optimizer = optim.Adam(Generator.parameters(G), lr=params['lr_g'], betas=(params['beta1'], params['beta2']))\n","D_optimizer = optim.Adam(Descriminator.parameters(D), lr=params['lr_g'], betas=(params['beta1'], params['beta2']))\n","\n","#Defining loss functions\n","Q_criterion = QLOSS(params['divergence']).to(device)\n","V_criterion = VLOSS(params['divergence']).to(device)\n","\n","#Model output\n","Ninner = 1\n","train_hist = {}\n","train_hist = {}\n","train_hist['D_loss_fake'] = []\n","train_hist['D_loss_true'] = []\n","train_hist['D_loss_total'] = []\n","train_hist['G_loss'] = []\n","\n","for epoch in range(params['max_epochs']):\n","  for inputs, labels in train_dataloader:\n","    #Sends data to device\n","    z_, x_ = inputs.to(device), labels.to(device)\n","    batch_sz = inputs.shape[0]\n","    y_real_, y_fake_ = torch.zeros(batch_sz, 1), torch.ones(batch_sz, 1)\n","    y_real_, y_fake_ = y_real_.to(device), y_fake_.to(device)\n","    #Update D network\n","    for i in range(Ninner):\n","      D_optimizer.zero_grad()\n","      D_real = D(x_.float())\n","      D_real_loss = -V_criterion(D_real)\n","\n","      G_ = G(z_)\n","      D_fake = D(G_)\n","      D_fake_loss = -Q_criterion(D_fake)\n","\n","      D_loss = D_real_loss + D_fake_loss\n","      D_loss.backward()\n","      D_optimizer.step()\n","\n","    # update G network\n","    for i in range(Ninner):\n","      G_optimizer.zero_grad()\n","      G_ = G(z_)\n","      D_fake = D(G_)\n","      G_loss = -V_criterion(D_fake)\n","\n","      G_loss.backward()\n","      G_optimizer.step()\n","\n","    train_hist['D_loss_fake'].append(D_fake_loss.item())\n","    train_hist['D_loss_true'].append(D_real_loss.item())\n","    train_hist['D_loss_total'].append(D_loss.item())\n","    train_hist['G_loss'].append(G_loss.item())\n","\n","  if(np.mod(epoch,50)==0):\n","    print(\"Epoch:\", epoch)\n","    print(\"\\tDloss =\",D_loss.detach().cpu().numpy(),\";Gloss=\",G_loss.detach().cpu().numpy())\n","    z_ = z_.to(device)\n","\n","plt.figure()\n","s=plt.plot(train_hist['D_loss_fake'],c='b')\n","s=plt.plot(train_hist['D_loss_true'],c='m')\n","s=plt.plot(train_hist['D_loss_total'],c='r')\n","s=plt.plot(train_hist['G_loss'],c='k')\n","s = plt.ylim((0,3))\n","s = plt.grid()\n","s=plt.legend(('Dloss_fake','D_loss_true','Discriminator loss','Generator loss'))"],"metadata":{"id":"q35kQ241HCZ5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Displays a tensor as an image\n","def imshow(img):\n","  img = (img - torch.min(img))/torch.max(img - torch.min(img))\n","  np_img = img.numpy()      # convert to numpy\n","  plt.imshow(np.transpose(np_img, (1,2,0)))\n","  plt.show()   "],"metadata":{"id":"NYEeEhOcTo9E","executionInfo":{"status":"ok","timestamp":1651511057904,"user_tz":300,"elapsed":615,"user":{"displayName":"Henry Bulluck","userId":"13348953596629209835"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["# Get random testing images\n","data_iter = iter(test_dataloader)\n","imgs, labels = data_iter.next()\n","# Show images (that are currently tensors) and their predictions\n","n_images = 0\n","imshow(torchvision.utils.make_grid(imgs[n_images,]))\n","_,labels = torch.max(labels,1)\n","imshow(torchvision.utils.make_grid(labels[n_images,]))\n","# forward pass through network\n","with torch.no_grad():\n","  outputs = G(imgs[n_images].unsqueeze(dim=1).to(device))\n","  _, predicted = torch.max(outputs, 1)\n","# predictions\n","imshow(torchvision.utils.make_grid(predicted.cpu().detach()))"],"metadata":{"id":"3_VlUd-2T1uS"},"execution_count":null,"outputs":[]}]}